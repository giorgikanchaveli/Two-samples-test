{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aec880ba",
   "metadata": {},
   "source": [
    "Here we compare 4 testing schemes: Dubey & Muller, Energy statistic (Szekely & Rizzo 2004), HIPM, WoW.\n",
    "\n",
    "In particular we compare power functions on the example of random probability measures from Fig 1 Dubey & Muller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2546c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "using KernelDensity\n",
    "\n",
    "\n",
    "include(\"distributions.jl\")\n",
    "\n",
    "include(\"distances/new_distance.jl\")\n",
    "include(\"distances/distance_Wasserstein.jl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de4eb4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134d6367",
   "metadata": {},
   "outputs": [],
   "source": [
    "function test_statistic_dm(pms_1::Vector{Normal}, pms_2::Vector{Normal})\n",
    "    # given two samples of probobability measures, compute the test statistic according to Dubey & Muller\n",
    "    n = length(pms_1)\n",
    "    # Recall that we assume that each of the sample is Normal distribution, and for W_2 metric we only need their means.\n",
    "    X = [pms_1[i].μ for i in 1:n] # collect all the means from first samples of probability measures\n",
    "    Y = [pms_2[i].μ for i in 1:n] # collect all the means from second samples of probability measures\n",
    "    \n",
    "    return test_statistic_dm(X, Y)\n",
    "end\n",
    "\n",
    "function test_statistic_dm(μ_1::Vector{Float64}, μ_2::Vector{Float64})\n",
    "    # given two samples of means of normal distributions, compute the test statistic according to Dubey & Muller\n",
    "    n = length(μ_1)\n",
    "    # Recall that we assume that each of the sample is Normal distribution, and for W_2 metric we only need their means.\n",
    "    X = μ_1 # collect all the means from first samples of probability measures\n",
    "    Y = μ_2 # collect all the means from second samples of probability measures\n",
    "\n",
    "    μ_hat_1 = mean(X)\n",
    "    μ_hat_2 = mean(Y)\n",
    "\n",
    "    v_hat_1 = mean((X .- μ_hat_1).^2)\n",
    "    v_hat_2 = mean((Y .- μ_hat_2).^2)\n",
    "\n",
    "    σ_hat_1_squared = mean((X .- μ_hat_1).^4) - (v_hat_1)^2\n",
    "    σ_hat_2_squared = mean((Y .- μ_hat_2).^4) - (v_hat_2)^2\n",
    "    \n",
    "    μ_hat_p = sum(X .+ Y) / (2 * n)\n",
    "    v_hat_p = sum( (X .- μ_hat_p).^2 .+ (Y .- μ_hat_p).^2 ) / (2 * n)\n",
    "\n",
    "    F_n = v_hat_p - v_hat_1/2 - v_hat_2/2\n",
    "    U_n = (1/4) * ((v_hat_1 - v_hat_2)^2) / (σ_hat_1_squared * σ_hat_2_squared) \n",
    "    \n",
    "    T_n = 2*n*U_n / (1/(2*σ_hat_1_squared) + 1/(2*σ_hat_2_squared) ) + 2 * n * (F_n^2) / (σ_hat_1_squared/4 + σ_hat_2_squared/4)\n",
    "\n",
    "    return T_n\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7655284",
   "metadata": {},
   "outputs": [],
   "source": [
    "function test_statistic_energy(pms_1::Vector{Normal}, pms_2::Vector{Normal})\n",
    "    # Recall that we assume that each of the sample is Normal distribution, and for W_2 metric we only need their means.\n",
    "    n = length(pms_1)\n",
    "    @assert n == length(pms_2) \"two samples of probability measures must have same size \"\n",
    "\n",
    "    X = [pms_1[i].μ for i in 1:n] # collect all the means from first samples of probability measures\n",
    "    Y = [pms_2[i].μ for i in 1:n] # collect all the means from second samples of probability measures\n",
    "\n",
    "    distances_X = [abs(X[i] - X[j]) for i in 1:n, j in 1:n]\n",
    "    distances_Y = [abs(Y[i] - Y[j]) for i in 1:n, j in 1:n]\n",
    "    distances_XY = [abs(X[i] - Y[j]) for i in 1:n, j in 1:n]\n",
    "\n",
    "\n",
    "    distance = 2 * mean(distances_XY) - mean(distances_X) - mean(distances_Y)\n",
    "    T_n = distance * n / 2\n",
    "    return T_n\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "function decide_energy_boostrap(pms_1::Vector{Normal}, pms_2::Vector{Normal}, n_boostrap::Int, θ = 0.05)\n",
    "    # given two samples of probobability measures, this function returns 0 or 1, i.e. either rejects or accepts \n",
    "    # null hypothesis for given significance level θ according to Energy statistic (Szekely & Rizzo 2004).\n",
    "\n",
    "    # n_boostrap: number of times we repeat bootstrap procedure to estimate the quantile of the test statistic\n",
    "\n",
    "    n_top = length(pms_1)\n",
    "    T_n = test_statistic_energy(pms_1, pms_2) # test statistic\n",
    "    # obtain quantile using bootstrap approach\n",
    "    T_n_boostrap = zeros(n_boostrap)\n",
    "    for s in 1:n_boostrap\n",
    "        allmeasures = vcat(pms_1, pms_2) # collect all probability measures into one vector\n",
    "        pms_1_boostrap = sample(allmeasures, n_top; replace=true) # resample from pooled probability measures\n",
    "        pms_2_boostrap = sample(allmeasures, n_top; replace=true) # resample from pooled probability measures\n",
    "        T_n_boostrap[s] = test_statistic_energy(pms_1_boostrap, pms_2_boostrap) # test statistic from boostraped sample\n",
    "    end\n",
    "    threshold = quantile(T_n_boostrap, 1-θ)\n",
    "    decision = 1.0*(T_n > threshold) # 1.0 if T_n > threshold, 0.0 otherwise.\n",
    "    return decision\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da231ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "function decide_dm_asympt(pms_1::Vector{Normal}, pms_2::Vector{Normal}, n_boostrap::Int, θ = 0.05)\n",
    "    # given two samples of probobability measures, this function returns 0 or 1, i.e. either rejects or accepts \n",
    "    # null hypothesis for given significance level θ according to Dubey & Muller.\n",
    "\n",
    "    # threshold is choosen from asymptotic distribution of test statistic which is chi-squared.\n",
    "\n",
    "    n_top = length(pms_1)\n",
    "    T_n = test_statistic_dm(pms_1, pms_2) # test statistic\n",
    "    \n",
    "    threshold = quantile(Chisq(1), 1 - θ) # obtain quantile from asymptotic distribution of test statistic\n",
    "    decision = 1.0*(T_n > threshold) # 1.0 if T_n > threshold, 0.0 otherwise.\n",
    "    return decision\n",
    "end\n",
    "\n",
    "function decide_dm_boostrap(pms_1::Vector{Normal}, pms_2::Vector{Normal}, n_boostrap::Int, θ = 0.05)\n",
    "    # given two samples of probobability measures, this function returns 0 or 1, i.e. either rejects or accepts \n",
    "    # null hypothesis for given significance level θ according to Dubey & Muller.\n",
    "\n",
    "    # n_boostrap: number of times we repeat bootstrap procedure to estimate the quantile of the test statistic\n",
    "\n",
    "    n_top = length(pms_1)\n",
    "    T_n = test_statistic_dm(pms_1, pms_2) # test statistic\n",
    "    # obtain quantile using bootstrap approach\n",
    "    T_n_boostrap = zeros(n_boostrap)\n",
    "    for s in 1:n_boostrap\n",
    "        allmeasures = vcat(pms_1, pms_2) # collect all probability measures into one vector\n",
    "        pms_1_boostrap = sample(allmeasures, n_top; replace=true) # resample from pooled probability measures\n",
    "        pms_2_boostrap = sample(allmeasures, n_top; replace=true) # resample from pooled probability measures\n",
    "        T_n_boostrap[s] = test_statistic_dm(pms_1_boostrap, pms_2_boostrap) # test statistic from boostraped sample\n",
    "    end\n",
    "    threshold = quantile(T_n_boostrap, 1-θ)\n",
    "    decision = 1.0*(T_n > threshold) # 1.0 if T_n > threshold, 0.0 otherwise.\n",
    "    return decision\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "function decide_dm_boostrap(pms_1::Vector{Float64}, pms_2::Vector{Float64}, n_boostrap::Int, θ = 0.05)\n",
    "    # given two samples of means of normal distributions with variance 1,\n",
    "    # this function returns 0 or 1, i.e. either rejects or accepts \n",
    "    # null hypothesis for given significance level θ according to Dubey & Muller.\n",
    "\n",
    "    # n_boostrap: number of times we repeat bootstrap procedure to estimate the quantile of the test statistic\n",
    "\n",
    "    n_top = length(pms_1)\n",
    "    T_n = test_statistic_dm(pms_1, pms_2) # test statistic\n",
    "    # obtain quantile using bootstrap approach\n",
    "    T_n_boostrap = zeros(n_boostrap)\n",
    "    for s in 1:n_boostrap\n",
    "        allmeasures = vcat(pms_1, pms_2) # collect all probability measures into one vector\n",
    "        pms_1_boostrap = sample(allmeasures, n_top; replace=true) # resample from pooled probability measures\n",
    "        pms_2_boostrap = sample(allmeasures, n_top; replace=true) # resample from pooled probability measures\n",
    "        T_n_boostrap[s] = test_statistic_dm(pms_1_boostrap, pms_2_boostrap) # test statistic from boostraped sample\n",
    "    end\n",
    "    threshold = quantile(T_n_boostrap, 1-θ)\n",
    "    decision = 1.0*(T_n > threshold) # 1.0 if T_n > threshold, 0.0 otherwise.\n",
    "    return decision\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a29bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_thresholds_permutation_hipm_wow(q_1::PPM, q_2::PPM, n_top::Int, n_bottom::Int, n_permutations::Int, θ::Float64)\n",
    "    # given laws of RPMs q_1, q_2, approximates the quantile of d(Q_{n,m}^1, Q_{n,m}^2) for both distance functions hipm,wow, using\n",
    "    # permutation approach. \n",
    "    permuted_samples_dlip = zeros(n_permutations) # store samples of distances\n",
    "    permuted_samples_ww = zeros(n_permutations) # store samples of distances\n",
    "\n",
    "    hier_sample_1, hier_sample_2 = generate_emp(q_1, n_top, n_bottom), generate_emp(q_2, n_top, n_bottom)\n",
    "    for k in 1:n_permutations\n",
    "        total_rows = vcat(hier_sample_1.atoms, hier_sample_2.atoms) # collect all rows\n",
    "        random_indices = randperm(2*n_top) # indices to distribute rows to new hierarchical meausures\n",
    "\n",
    "        atoms_1 = total_rows[random_indices[1:n_top],:] # first rows indexed by n_top random indices to the atoms_1\n",
    "        atoms_2 = total_rows[random_indices[n_top+1:end],:] # first rows indexed by n_top random indices to the atoms_2\n",
    "\n",
    "        # now we need to make sure that we get the proper bounds on the all observations from hierarchical samples\n",
    "        a_1 = minimum(atoms_1) # left end of an interaval where observations in hier_sample_1 take values\n",
    "        b_1 = maximum(atoms_1) # right end of an interaval where observations in hier_sample_1 take values\n",
    "\n",
    "        a_2 = minimum(atoms_2) # left end of an interaval where in hier_sample_2 observations take values\n",
    "        b_2 = maximum(atoms_2) # right end of an interaval where in hier_sample_2 observations take values\n",
    "\n",
    "        a,b = minimum([a_1,a_2]), maximum([b_1,b_2])\n",
    "        hier_sample_1_permuted = emp_ppm(atoms_1, n_top, n_bottom, a, b)\n",
    "        hier_sample_2_permuted = emp_ppm(atoms_2, n_top, n_bottom, a, b)\n",
    "\n",
    "        \n",
    "        permuted_samples_dlip[k] = dlip(hier_sample_1_permuted, hier_sample_2_permuted)\n",
    "        permuted_samples_ww[k] = ww(hier_sample_1_permuted, hier_sample_2_permuted)\n",
    "    end\n",
    "\n",
    "    threshold_hipm = quantile(permuted_samples_dlip, 1 - θ)\n",
    "    threshold_wow = quantile(permuted_samples_ww, 1 - θ)\n",
    "\n",
    "    return threshold_hipm, threshold_wow\n",
    "end\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "function get_thresholds_boostrap_hipm_wow(q_1::PPM, q_2::PPM, n_top::Int, n_bottom::Int, n_boostrap::Int, θ::Float64)\n",
    "    # given laws of RPMs q_1, q_2, approximates the quantile of d(Q_{n,m}^1, Q_{n,m}^2) for both distance functions hipm,wow, using\n",
    "    # permutation approach. \n",
    "    permuted_samples_dlip = zeros(n_boostrap) # store samples of distances\n",
    "    permuted_samples_ww = zeros(n_boostrap) # store samples of distances\n",
    "\n",
    "    hier_sample_1, hier_sample_2 = generate_emp(q_1, n_top, n_bottom), generate_emp(q_2, n_top, n_bottom)\n",
    "    for k in 1:n_boostrap\n",
    "        total_rows = vcat(hier_sample_1.atoms, hier_sample_2.atoms) # collect all rows\n",
    "        \n",
    "        indices_1 = sample(1:2*n_top, n_top; replace = true)\n",
    "        indices_2 = sample(1:2*n_top, n_top; replace = true)\n",
    "        atoms_1 = total_rows[indices_1,:]  # resample from pooled hierarchical sample\n",
    "        atoms_2 = total_rows[indices_2,:]  # resample from pooled hierarchical sample\n",
    "        \n",
    "        # now we need to make sure that we get the proper bounds on the all observations from hierarchical samples\n",
    "        a_1 = minimum(atoms_1) # left end of an interaval where observations in hier_sample_1 take values\n",
    "        b_1 = maximum(atoms_1) # right end of an interaval where observations in hier_sample_1 take values\n",
    "\n",
    "        a_2 = minimum(atoms_2) # left end of an interaval where in hier_sample_2 observations take values\n",
    "        b_2 = maximum(atoms_2) # right end of an interaval where in hier_sample_2 observations take values\n",
    "\n",
    "        a,b = minimum([a_1,a_2]), maximum([b_1,b_2])\n",
    "        hier_sample_1_permuted = emp_ppm(atoms_1, n_top, n_bottom, a, b)\n",
    "        hier_sample_2_permuted = emp_ppm(atoms_2, n_top, n_bottom, a, b)\n",
    "\n",
    "        \n",
    "        permuted_samples_dlip[k] = dlip(hier_sample_1_permuted, hier_sample_2_permuted)\n",
    "        permuted_samples_ww[k] = ww(hier_sample_1_permuted, hier_sample_2_permuted)\n",
    "    end\n",
    "\n",
    "    threshold_hipm = quantile(permuted_samples_dlip, 1 - θ)\n",
    "    threshold_wow = quantile(permuted_samples_ww, 1 - θ)\n",
    "\n",
    "    return threshold_hipm, threshold_wow\n",
    "end\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da842267",
   "metadata": {},
   "outputs": [],
   "source": [
    "using RCall\n",
    "\n",
    "\n",
    "function denanova_from_r(mu_1::Vector{Float64}, mu_2::Vector{Float64};\n",
    "                           sd::Float64 = 1.0, nq::Int = 51, qmin=0.01, qmax=0.99,\n",
    "                           n_boostrap::Int = 1000, seed = 1234, theta::Float64 = 0.05)\n",
    "\n",
    "    @rput mu_1 mu_2 sd nq qmin qmax n_boostrap seed\n",
    "\n",
    "    R\"\"\"\n",
    "    # if (!requireNamespace(\"frechet\", quietly = TRUE)) {\n",
    "    #   install.packages(\"frechet\", repos=\"https://cloud.r-project.org\")\n",
    "    # }\n",
    "\n",
    "    set.seed(seed)\n",
    "\n",
    "    n1 <- length(mu_1)\n",
    "    n2 <- length(mu_2)\n",
    "    qSup <- seq(qmin, qmax, length.out = nq)\n",
    "\n",
    "    Y1 <- lapply(seq_len(n1), function(i) qnorm(qSup, mean = mu_1[i], sd = sd))\n",
    "    Y2 <- lapply(seq_len(n2), function(i) qnorm(qSup, mean = mu_2[i], sd = sd))\n",
    "\n",
    "    Ly <- c(Y1, Y2)\n",
    "    Lx <- qSup\n",
    "    group <- c(rep(1, n1), rep(2, n2))\n",
    "\n",
    "    res <- frechet::DenANOVA(qin = Ly, supin = Lx, group = group,\n",
    "                    optns = list(boot = TRUE, R = n_boostrap))\n",
    "\n",
    "    p_asym <- res$pvalAsy; p_boot <- res$pvalBoot\n",
    "    \"\"\"\n",
    "    @rget p_asym p_boot\n",
    "    return 1 * (p_boot < theta)\n",
    "end\n",
    "\n",
    "\n",
    "function rej_rates_denanova_my(q_1::PPM, q_2::PPM, S::Int, n_top::Int, n_boostrap::Int, θ::Float64)\n",
    "    # obtain rejection rates of denanova and my implementation of dm with boostrap\n",
    "    # for given laws of RPMs q_1 and q_2\n",
    "    # S : number of times we simulate two samples from given laws of RPM\n",
    "    # n_top : number of probability measures we simulate from each q\n",
    "    # n_boostrap : number of times we repeat bootstrap procedure to estimate the quantile of the test statistic.\n",
    "    \n",
    "    rej_rate_denanova, rej_rate_my = 0.0, 0.0\n",
    "\n",
    "    println(\"law of RPMS are: $(q_1)\")\n",
    "    println(\"$(q_2)\")\n",
    "\n",
    "    for s in 1:S\n",
    "        mu_1, mu_2 = [pm_1.μ for pm_1 in generate_prob_measures(q_1, n_top)], [pm_2.μ for pm_2 in generate_prob_measures(q_2, n_top)]\n",
    "        println(\"s is $(s)\")\n",
    "        rej_rate_denanova += denanova_from_r(mu_1, mu_2; n_boostrap=100, theta = θ)\n",
    "        rej_rate_my += decide_dm_boostrap(mu_1, mu_2, n_boostrap, θ)\n",
    "    end\n",
    "    rej_rate_denanova /= S\n",
    "    rej_rate_my /= S\n",
    "    return rej_rate_denanova, rej_rate_my\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea504bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "function rejection_rate(q_1::PPM, q_2::PPM, S::Int, n_top::Int, n_bottom::Int, n_boostrap::Int, θ::Float64, boostrap::Bool=true)\n",
    "    # Given two laws of RPM, q_1 and q_2, estimate the rejection rate for given significance level θ for 3 testing schemes:\n",
    "    # Dubey & Mueller, HIPM, WoW, Energy statistic\n",
    "\n",
    "    # S : number of times we simulate two samples from given laws of RPM\n",
    "    # n_top : number of probability measures we simulate from each q\n",
    "    # n_bottom : number of random variables we simulate from each of the probability measure from q\n",
    "    # n_boostrap : number of times we repeat bootstrap procedure to estimate the quantile of the test statistic. Note that this is \n",
    "    #              same as number of permutations for HIPM and WoW.\n",
    "    \n",
    "    rej_rate_dm, rej_rate_hipm, rej_rate_wow, rej_rate_energy = 0.0, 0.0, 0.0, 0.0\n",
    "\n",
    "    # Instead of getting the threshold for HIPM and WoW based on hierarchical sample everytime, for fixed q_1 and q_2, we obtain\n",
    "    # threshold once from some generated hierarchical samples and then use it for other hierarchical samples.\n",
    "    if boostrap\n",
    "        threshold_hipm, threshold_wow = get_thresholds_boostrap_hipm_wow(q_1, q_2, n_top, n_bottom, n_boostrap, θ) \n",
    "    else\n",
    "        threshold_hipm, threshold_wow = get_thresholds_permutation_hipm_wow(q_1, q_2, n_top, n_bottom, n_boostrap, θ) \n",
    "    end\n",
    "\n",
    "    println(\"law of RPMS are: $(q_1)\")\n",
    "    println(\"$(q_2)\")\n",
    "\n",
    "    for s in 1:S\n",
    "        println(\"S is $(s)\")\n",
    "        pms_1, pms_2 = generate_prob_measures(q_1, n_top), generate_prob_measures(q_2, n_top) # generate n_top probability measures\n",
    "                                            # from q_1 and q_2\n",
    "\n",
    "        mu_1, mu_2 = [pm_1.μ for pm_1 in pms_1], [pm_2.μ for pm_2 in pms_2] # collect means of all probability measures in pms_1 and pms_2\n",
    "\n",
    "        hier_sample_1, hier_sample_2 = generate_emp(pms_1, n_top, n_bottom), generate_emp(pms_2, n_top, n_bottom) # generate n_bottom\n",
    "                                            # random variables from each probability measures in pms_1 and pms_2\n",
    "        # endpoints of the sample space for observatinos from hier_sample_1 and hier_sample_2 might be different, so we fix it\n",
    "        a = minimum([minimum(hier_sample_1.atoms), minimum(hier_sample_2.atoms)])\n",
    "        b = maximum([maximum(hier_sample_1.atoms), maximum(hier_sample_2.atoms)])\n",
    "        hier_sample_1.a = a\n",
    "        hier_sample_1.b = b\n",
    "        hier_sample_2.a = a\n",
    "        hier_sample_2.b = b\n",
    "\n",
    "        # record if testing schemes reject\n",
    "        rej_rate_dm += denanova_from_r(mu_1, mu_2; n_boostrap=n_boostrap, theta = θ)  \n",
    "        rej_rate_hipm += 1*(dlip(hier_sample_1, hier_sample_2) > threshold_hipm)\n",
    "        rej_rate_wow += 1*(ww(hier_sample_1, hier_sample_2) > threshold_wow)\n",
    "\n",
    "        rej_rate_energy += decide_energy_boostrap(pms_1, pms_2, n_boostrap, θ)\n",
    "    end\n",
    "    rej_rate_dm /= S\n",
    "    rej_rate_hipm /= S\n",
    "    rej_rate_wow /= S\n",
    "    rej_rate_energy /= S\n",
    "    return rej_rate_dm,  rej_rate_hipm, rej_rate_wow, rej_rate_energy\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e689fce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b4483e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d11cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "function power_per_parameter(δs::Vector{Float64}, power::Function)\n",
    "    # given δs and power function, computes power function per each δ and returns rejection rates per each δ for each\n",
    "    # testing scheme: DM, HIPM, WoW, Energy statistic,\n",
    "    rej_rates = zeros(length(δs), 4) # per each delta and testing scheme\n",
    "\n",
    "    for i in 1:length(δs)\n",
    "        rej_rates[i,:] .= power(δs[i]) # returns rejection rate for δ[i] for each testing scheme\n",
    "    end\n",
    "    return rej_rates\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1d572a",
   "metadata": {},
   "source": [
    "# Figure 1, Left, of the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2450df92",
   "metadata": {},
   "source": [
    "Now we plot the power function per $\\delta$ as it is in their paper for \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38125311",
   "metadata": {},
   "source": [
    "We let $ n = 35 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83d0fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79274a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top, n_bottom = 5,2\n",
    "n_boostrap = 5\n",
    "S = 20\n",
    "θ = 0.05\n",
    "\n",
    "Random.seed!(1234) # for reproducibility\n",
    "\n",
    "# maybe variance should be sqrt(0.5) instead of 0.5 ???\n",
    "power_tnormal_normal(δ) = rejection_rate(tnormal_normal(0.0, 0.5, -10.0, 10.0), tnormal_normal(δ, 0.5, -10.0, 10.0),S, n_top, n_bottom, n_boostrap, θ, true) # powers per δ for each testing scheme\n",
    "\n",
    "δs = collect(-1.0:0.1:1.0)\n",
    "rejection_rates_tnormal_normal = power_per_parameter(δs, power_tnormal_normal)\n",
    "plot_power = plot(title = \"Power of 4 testing schemes\", xlabel = \"δ\", ylabel = \"Power\", xlims=(-1.0, 1.1), ylims = (-0.1, 1.1))\n",
    "plot!(plot_power, δs, rejection_rates_tnormal_normal[:,1], label = \"dm\", color = \"red\")\n",
    "plot!(plot_power, δs, rejection_rates_tnormal_normal[:,2], label = \"hipm\", color = \"green\")\n",
    "plot!(plot_power, δs, rejection_rates_tnormal_normal[:,3], label = \"wow\", color = \"brown\")\n",
    "plot!(plot_power, δs, rejection_rates_tnormal_normal[:,4], label = \"Energy\", color = \"blue\")\n",
    "filepath = joinpath(pwd(), \"frechet/figure1\")\n",
    "savefig(plot_power,joinpath(filepath, \"power_tnormal_normal_n_top=$(n_top)_n_bottom=$(n_bottom)_S=$(S)_nboostrap=$(n_boostrap).png\"))\n",
    "# # #minimum_power_dm = minimum(power_function_dm[])\n",
    "# # #hline!([minimum_power_dm], color=:red, linestyle=:dash, label=\"minimum power for dm\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4bccc2",
   "metadata": {},
   "source": [
    "Now for $n = 100$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6e8899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_top, n_bottom = 100,2000\n",
    "# n_boostrap = 200\n",
    "# S = 100\n",
    "# θ = 0.05\n",
    "\n",
    "# Random.seed!(1234) # for reproducibility\n",
    "\n",
    "# # maybe variance should be sqrt(0.5) instead of 0.5 ???\n",
    "# power_tnormal_normal(δ) = rejection_rate(tnormal_normal(0.0, 0.5, -10.0, 10.0), tnormal_normal(δ, 0.5, -10.0, 10.0),S, n_top, n_bottom, n_boostrap, θ,true) # powers per δ for each testing scheme\n",
    "\n",
    "# δs = collect(-1.0:0.1:1.0)\n",
    "# rejection_rates_tnormal_normal = power_per_parameter(δs, power_tnormal_normal)\n",
    "# fig_1 = plot(title = \"Power of 4 testing schemes\", xlabel = \"δ\", ylabel = \"Power\", xlims=(-1.0, 1.1), ylims = (-0.1, 1.1))\n",
    "# plot!(fig_1, δs, rejection_rates_tnormal_normal[:,1], label = \"dm\", color = \"red\")\n",
    "# plot!(fig_1, δs, rejection_rates_tnormal_normal[:,2], label = \"hipm\", color = \"green\")\n",
    "# plot!(fig_1, δs, rejection_rates_tnormal_normal[:,3], label = \"wow\", color = \"brown\")\n",
    "# plot!(fig_1, δs, rejection_rates_tnormal_normal[:,4], label = \"Energy\", color = \"blue\")\n",
    "# filepath = joinpath(pwd(), \"frechet/figure1\")\n",
    "# savefig(fig_1,joinpath(filepath, \"power_tnormal_normal_n_top=$(n_top)_n_bottom=$(n_bottom)_S=$(S)_nboostrap=$(n_boostrap).png\"))\n",
    "\n",
    "# # # #minimum_power_dm = minimum(power_function_dm[])\n",
    "# # # #hline!([minimum_power_dm], color=:red, linestyle=:dash, label=\"minimum power for dm\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573ea4e0",
   "metadata": {},
   "source": [
    "# Figure 1, Right of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb88a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_top, n_bottom = 100,2000\n",
    "# n_boostrap = 100\n",
    "# S = 100\n",
    "# θ = 0.05\n",
    "\n",
    "# Random.seed!(1234) # for reproducibility\n",
    "\n",
    "# # maybe variance should be sqrt(0.5) instead of 0.5 ???\n",
    "# power_tnormal_normal(τ) = rejection_rate(tnormal_normal(0.0, 0.2, -10.0, 10.0), tnormal_normal(0.0, 0.2*τ, -10.0, 10.0),S, n_top, n_bottom, n_boostrap, θ, true) # powers per δ for each testing scheme\n",
    "\n",
    "# τs = collect(0.5:0.25:3.0)\n",
    "# rejection_rates_tnormal_normal = power_per_parameter(τs, power_tnormal_normal)\n",
    "# fig_2 = plot(title = \"Power of 4 testing schemes\", xlabel = \"τ\", ylabel = \"Power\", xlims=(0.0, 3.1), ylims = (-0.1, 1.1))\n",
    "# plot!(fig_2, τs, rejection_rates_tnormal_normal[:,1], label = \"dm\", color = \"red\")\n",
    "# plot!(fig_2, τs, rejection_rates_tnormal_normal[:,2], label = \"hipm\", color = \"green\")\n",
    "# plot!(fig_2, τs, rejection_rates_tnormal_normal[:,3], label = \"wow\", color = \"brown\")\n",
    "# plot!(fig_2, τs, rejection_rates_tnormal_normal[:,4], label = \"Energy\", color = \"blue\")\n",
    "# filepath = joinpath(pwd(), \"frechet/figure1\")\n",
    "# savefig(fig_2,joinpath(filepath, \"power_tnormal_normal_varying_variance_n_top=$(n_top)_n_bottom=$(n_bottom)_S=$(S)_nboostrap=$(n_boostrap).png\"))\n",
    "\n",
    "# # # #minimum_power_dm = minimum(power_function_dm[])\n",
    "# # # #hline!([minimum_power_dm], color=:red, linestyle=:dash, label=\"minimum power for dm\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c384996",
   "metadata": {},
   "source": [
    "# Example where DM should fail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf0cad0",
   "metadata": {},
   "source": [
    "Now let us do same simulations on different law of random probability measure: \n",
    "\n",
    "$\\mu \\sim Normal(\\delta, \\sigma)$ and define $ P = Normal(\\mu, 1).$\n",
    "\n",
    "In this case, if I have $Q^1,Q^2$ where they generate means from $Normal(0.0, 1.0), Normal(0.0,1.5)$, then they are different but Frechet means are same. So power should be low"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dc22de",
   "metadata": {},
   "source": [
    "With Boostrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d79b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_top, n_bottom = 700,200\n",
    "# n_boostrap = 40\n",
    "# S = 40\n",
    "# θ = 0.05\n",
    "\n",
    "# Random.seed!(1234) # for reproducibility\n",
    "\n",
    "# a, b = 0.0, 2.0\n",
    "# μ, σ = 1.0, sqrt(1/3)\n",
    "\n",
    "# mixture(λ) = mixture_ppm(normal_normal(μ,σ), uniform_normal(a,b), λ) # low lambda means more to second distribution which here is uniform normal\n",
    "# power_normal_uniform(λ) = rejection_rate(normal_normal(μ,σ), mixture(λ), S, n_top, n_bottom, n_boostrap, θ, true) \n",
    "\n",
    "# λs = collect(0.0:0.25:1.0)\n",
    "# rejection_rates_normal_uniform = power_per_parameter(λs, power_normal_uniform)\n",
    "\n",
    "# # # #minimum_power_dm = minimum(power_function_dm[])\n",
    "# # # #hline!([minimum_power_dm], color=:red, linestyle=:dash, label=\"minimum power for dm\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a7c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_counter_example = plot(title = \"Power of 4 testing schemes\", xlabel = \"λ\", ylabel = \"Power\", xlims=(-0.1, 1.1), ylims = (-0.1, 1.1))\n",
    "# scatter!(fig_counter_example, λs, rejection_rates_normal_uniform[:,1], label = \"dm\", color = \"red\")\n",
    "# scatter!(fig_counter_example, λs, rejection_rates_normal_uniform[:,2], label = \"hipm\", color = \"green\")\n",
    "# scatter!(fig_counter_example, λs, rejection_rates_normal_uniform[:,3], label = \"wow\", color = \"brown\")\n",
    "# scatter!(fig_counter_example, λs, rejection_rates_normal_uniform[:,4], label = \"Energy\", color = \"blue\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d3e46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_counter_example = plot(title = \"Power of 4 testing schemes\", xlabel = \"λ\", ylabel = \"Power\", xlims=(-0.1, 1.1), ylims = (-0.1, 1.1))\n",
    "# plot!(fig_counter_example, λs, rejection_rates_normal_uniform[:,1], label = \"dm\", color = \"red\")\n",
    "# plot!(fig_counter_example, λs, rejection_rates_normal_uniform[:,2], label = \"hipm\", color = \"green\")\n",
    "# plot!(fig_counter_example, λs, rejection_rates_normal_uniform[:,3], label = \"wow\", color = \"brown\")\n",
    "# plot!(fig_counter_example, λs, rejection_rates_normal_uniform[:,4], label = \"Energy\", color = \"blue\")\n",
    "\n",
    "# filepath = joinpath(pwd(), \"frechet/counterexample\")\n",
    "# savefig(fig_counter_example,joinpath(filepath, \"power_normal_uniform_counter_example_boostrap_n_top=$(n_top)_n_bottom=$(n_bottom)_S=$(S)_nboostrap=$(n_boostrap).png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7b491c",
   "metadata": {},
   "source": [
    "# With permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91362dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_top, n_bottom = 10,2000\n",
    "# n_permutations = 7\n",
    "# S = 10\n",
    "# θ = 0.05\n",
    "\n",
    "# Random.seed!(1234) # for reproducibility\n",
    "\n",
    "# a, b = 0.0, 2.0\n",
    "# μ, σ = 1.0, sqrt(1/3)\n",
    "\n",
    "# mixture(λ) = mixture_ppm(normal_normal(μ,σ), uniform_normal(a,b), λ) # low lambda means more to second distribution which here is uniform normal\n",
    "# power_normal_uniform(λ) = rejection_rate(normal_normal(μ,σ), mixture(λ), S, n_top, n_bottom, n_boostrap, θ, false) \n",
    "\n",
    "# λs = collect(0.0:0.25:1.0)\n",
    "# rejection_rates_normal_uniform = power_per_parameter(λs, power_normal_uniform)\n",
    "\n",
    "# # # #minimum_power_dm = minimum(power_function_dm[])\n",
    "# # # #hline!([minimum_power_dm], color=:red, linestyle=:dash, label=\"minimum power for dm\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9349759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_counter_example = plot(title = \"Power of 4 testing schemes\", xlabel = \"λ\", ylabel = \"Power\", xlims=(-0.1, 1.1), ylims = (-0.1, 1.1))\n",
    "# scatter!(fig_counter_example, λs, rejection_rates_normal_uniform[:,1], label = \"dm\", color = \"red\")\n",
    "# scatter!(fig_counter_example, λs, rejection_rates_normal_uniform[:,2], label = \"hipm\", color = \"green\")\n",
    "# scatter!(fig_counter_example, λs, rejection_rates_normal_uniform[:,3], label = \"wow\", color = \"brown\")\n",
    "# scatter!(fig_counter_example, λs, rejection_rates_normal_uniform[:,4], label = \"Energy\", color = \"blue\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ec014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_counter_example = plot(title = \"Power of 4 testing schemes\", xlabel = \"λ\", ylabel = \"Power\", xlims=(-0.1, 1.1), ylims = (-0.1, 1.1))\n",
    "# plot!(fig_counter_example, λs, rejection_rates_normal_uniform[:,1], label = \"dm\", color = \"red\")\n",
    "# plot!(fig_counter_example, λs, rejection_rates_normal_uniform[:,2], label = \"hipm\", color = \"green\")\n",
    "# plot!(fig_counter_example, λs, rejection_rates_normal_uniform[:,3], label = \"wow\", color = \"brown\")\n",
    "# plot!(fig_counter_example, λs, rejection_rates_normal_uniform[:,4], label = \"Energy\", color = \"blue\")\n",
    "\n",
    "\n",
    "# filepath = joinpath(pwd(), \"frechet/counterexample\")\n",
    "# savefig(fig_counter_example,joinpath(filepath, \"power_normal_uniform_counter_example_permutation_n_top=$(n_top)_n_bottom=$(n_bottom)_S=$(S)_permutations=$(n_permutations).png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6072935",
   "metadata": {},
   "source": [
    "# Let us test if my code is same as the code written in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85293252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2a1978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193f824b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0208e380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141da71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n_top, n_bottom = 100,2000\n",
    "n_boostrap = 200\n",
    "S = 200\n",
    "θ = 0.05\n",
    "\n",
    "Random.seed!(1234) # for reproducibility\n",
    "δs = collect(-1.0:0.05:1.0)\n",
    "rej_rate_denanova_per_delta, rej_rate_my_per_delta = zeros(length(δs)), zeros(length(δs))\n",
    "for (i, δ) in enumerate(δs)\n",
    "    q_1, q_2 = tnormal_normal(0.0, 0.5, -10.0, 10.0), tnormal_normal(δ, 0.5, -10.0, 10.0)\n",
    "\n",
    "    rej_rate_denanova, rej_rate_my = rej_rates_denanova_my(q_1, q_2, S, n_top, n_boostrap, θ)\n",
    "    rej_rate_denanova_per_delta[i] = rej_rate_denanova\n",
    "    rej_rate_my_per_delta[i] = rej_rate_my\n",
    "end\n",
    "fig_denanova_vs_my = plot(title = \"Power of DenANOVA vs my implementation of DM\", xlabel = \"δ\", ylabel = \"Power\", xlims=(-1.1, 1.1), ylims = (-0.1, 1.1))\n",
    "plot!(fig_denanova_vs_my, δs, rej_rate_denanova_per_delta, label = \"DenANOVA\", color = \"red\")\n",
    "plot!(fig_denanova_vs_my, δs, rej_rate_my_per_delta, label = \"My DM\", color = \"blue\")\n",
    "\n",
    "# # maybe variance should be sqrt(0.5) instead of 0.5 ???\n",
    "# power_tnormal_normal(δ) = rejection_rate(tnormal_normal(0.0, 0.5, -10.0, 10.0), tnormal_normal(δ, 0.5, -10.0, 10.0),S, n_top, n_bottom, n_boostrap, θ, true) # powers per δ for each testing scheme\n",
    "\n",
    "# δs = collect(-1.0:0.1:1.0)\n",
    "# rejection_rates_tnormal_normal = power_per_parameter(δs, power_tnormal_normal)\n",
    "# plot_power = plot(title = \"Power of 4 testing schemes\", xlabel = \"δ\", ylabel = \"Power\", xlims=(-1.0, 1.1), ylims = (-0.1, 1.1))\n",
    "# plot!(plot_power, δs, rejection_rates_tnormal_normal[:,1], label = \"dm\", color = \"red\")\n",
    "# plot!(plot_power, δs, rejection_rates_tnormal_normal[:,2], label = \"hipm\", color = \"green\")\n",
    "# plot!(plot_power, δs, rejection_rates_tnormal_normal[:,3], label = \"wow\", color = \"brown\")\n",
    "# plot!(plot_power, δs, rejection_rates_tnormal_normal[:,4], label = \"Energy\", color = \"blue\")\n",
    "# filepath = joinpath(pwd(), \"frechet/figure1\")\n",
    "# savefig(plot_power,joinpath(filepath, \"power_tnormal_normal_n_top=$(n_top)_n_bottom=$(n_bottom)_S=$(S)_nboostrap=$(n_boostrap).png\"))\n",
    "# # # #minimum_power_dm = minimum(power_function_dm[])\n",
    "# # # #hline!([minimum_power_dm], color=:red, linestyle=:dash, label=\"minimum power for dm\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c19fdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "rej_rate_denanova_per_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c284d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = abs.(rej_rate_my_per_delta .- rej_rate_denanova_per_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d7bc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(δs, differences, title = \"Difference between DenANOVA and my implementation of DM\", xlabel = \"δ\",ylabel = \"Absolute difference in power\", xlims=(-1.1, 1.1), ylims = (-0.05, 0.2), label = \"Absolute difference\", color = \"purple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4fbe7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.6",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
